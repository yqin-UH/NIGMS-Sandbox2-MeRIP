{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cfa998-06b6-4b42-ae3a-b4e011750d31",
   "metadata": {},
   "source": [
    "# Module 5. Running the MeRIP-seq Pipeline on AWS Batch with Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126cb07-34ee-4780-838f-872015a882b3",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ea992-faa6-4705-8384-eb5d81f5daff",
   "metadata": {},
   "source": [
    "In this module, we will run a MeRIP-seq (m6A-seq) pipeline using Nextflow on [AWS Batch](https://aws.amazon.com/batch/). If you completed the other tutorials in this repo, you will see that it is similar to submodule 4, but instead of running the nextflow pipeline locally in the SageMaker notebook, we switch to AWS Batch, which enables scalable, reproducible, and cloud-based analysis with minimal infrastructure management.\n",
    "\n",
    "We will build upon concepts introduced in previous modules:\n",
    "- Submodules 1â€“3: Local data processing and MeRIP-seq basics\n",
    "- Submodule 4: Running the pipeline with Nextflow on a local machine\n",
    "- **Submodule 5**: Transitioning the workflow to **AWS Batch**\n",
    "\n",
    "#### About AWS Batch\n",
    "AWS Batch will create the needed permissions, roles and resources to run Nextflow in a serverless manner. You can set up AWS Batch manually or deploy it **automatically** with a stack template. Please see **Setting up AWS Batch** in the Get Started section below to learn more about how to use it.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56d718a8",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "#### Python requirements\n",
    "+ Python >= 3.8\n",
    "\n",
    "#### AWS requirements\n",
    "+ Please ensure you have a VPC, subnets, and security group set up before running this tutorial.\n",
    "+ Role with AdministratorAccess, AmazonSageMakerFullAccess, S3 access and AWSBatchServiceRole.\n",
    "+ Instance Role with AmazonECS_FullAccess, AmazonEC2ContainerRegistryFullAccess, and S3 access.\n",
    "+ If you do not have the required set-up for AWS Batch please follow this tutorial [here](https://github.com/STRIDES/NIHCloudLabAWS/blob/zbyosufzai-awsbatch-1/notebooks/AWSBatch/Intro_AWS_Batch.ipynb#install_nextflow).\n",
    "+ ***When making the instance role, make another for SageMaker notebooks with the following permissions: AdminstratorAccess, AmazonEC2ContainerRegistryFullAccess, AmazonECS_FullAccess, AmazonS3FullAccess, AmazonSageMakerFullAccess, and AWSBatchServiceRole.***\n",
    "+ It is recommended that specific permission to folders are added through inline policy. An example of the JSON is below:\n",
    "\n",
    "<pre>\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowSageMakerS3Access\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:GetBucketLocation\",\n",
    "                \"s3:CreateBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::batch-bucket\",\n",
    "                \"arn:aws:s3:::batch-bucket/*\",\n",
    "                \"arn:aws:s3:::nigms-sandbox-healthomics\",\n",
    "                \"arn:aws:s3:::nigms-sandbox-healthomics/*\",\n",
    "                \"arn:aws:s3:::ngi-igenomes\",\n",
    "                \"arn:aws:s3:::ngi-igenomes/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "</pre>\n",
    "For AWS bucket naming conventions, please click [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html).\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"border: 1px solid #ffe69c; padding: 0px; border-radius: 4px;\">\n",
    "  <div style=\"background-color: #fff3cd; padding: 5px; font-weight: bold;\">\n",
    "    <i class=\"fas fa-exclamation-triangle\" style=\"color: #664d03;margin-right: 5px;\"></i><a style=\"color: #664d03\">Before using AWS Batch </a>\n",
    "  </div>\n",
    "  <p style=\"margin-left: 5px;\">\n",
    "Before begining this tutorial, if you do not have required roles, policies, permissions or compute environment and would like to <b>manually</b> set those up please click <a href=\"https://github.com/NIGMS/NIGMS-Sandbox/blob/main/docs/AWS-Batch-Setup.md\">here</a> to set that up.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f940d3ca",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "### Step 0. Setting up AWS Batch\n",
    "AWS Batch manages the provisioning of compute environments (EC2, Fargate), container orchestration, job queues, IAM roles, and permissions. We can deploy a full environment either:\n",
    "- Automatically using a preconfigured AWS CloudFormation stack (**recommended**)\n",
    "- Manually by setting up roles, queues, and buckets\n",
    "The Launch Stack button below will take you to the cloud formation create stack webpage with the template with required resources already linked. \n",
    "\n",
    "If you prefer to skip manual deployment and deploy automatically in the cloud, click the **Launch Stack** button below. For a walkthrough of the screens during automatic deployment please click [here](https://github.com/NIGMS/NIGMS-Sandbox/blob/main/docs/HowToLaunchAWSBatch.md). The deployment should take ~5 min and then the resources will be ready for use. \n",
    "\n",
    "[![Launch Stack](images/LaunchStack.jpg)](https://console.aws.amazon.com/cloudformation/home?#/stacks/new?stackName=aws-batch-nigms&templateURL=https://nigms-sandbox.s3.us-east-1.amazonaws.com/cf-templates/AWSBatch_template.yaml )\n",
    "\n",
    "### Step 1. Install dependencies, update paths and create a new S3 Bucket to store input and output files\n",
    "After setting up a AWS CloudFormation stack, need to let the nextflow workflow to know where are those resrouces by providing the configuration:\n",
    "<div style=\"border: 1px solid #e57373; padding: 0px; border-radius: 4px;\">\n",
    "  <div style=\"background-color: #ffcdd2; padding: 5px; \">\n",
    "    <i class=\"fas fa-exclamation-triangle\" style=\"color: #b71c1c;margin-right: 5px;\"></i><a style=\"color: #b71c1c\"><b>Important</b> - Customize Required</a>\n",
    "  </div>\n",
    "  <p style=\"margin-left: 5px;\">\n",
    "Replace the <b>stack name</b> to the stack that you just created. <code>STACK_NAME = \"your-stack-name-here\"</code>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857ebd4-8e83-4bc9-8344-b92d79cf1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfine a stack name variable\n",
    "STACK_NAME = \"aws-batch-nigms-test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# Get account ID and region \n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb43e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable names \n",
    "# These variables should come from the Intro AWS Batch tutorial (or leave as-is if using the launch stack button)\n",
    "BUCKET_NAME = f\"{STACK_NAME}-batch-bucket-{account_id}\"\n",
    "AWS_QUEUE = f\"{STACK_NAME}-JobQueue\"\n",
    "INPUT_FOLDER = 'nigms-sandbox/ovarian-cancer-example-fastqs'\n",
    "AWS_REGION = region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3928468-33b8-4534-8f86-7eedfa699993",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defbe3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Nextflow\n",
    "! mamba install -y -c conda-forge -c bioconda nextflow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f811f-09bb-4956-9277-99ad2fe9b329",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Install Java and Nextflow if needed in other systems</summary>\n",
    "If using other system other than AWS SageMaker Notebook, you might need to install java and nextflow using the code below:\n",
    "<br> <i># Install java</i><pre>\n",
    "    sudo apt update\n",
    "    sudo apt-get install default-jdk -y\n",
    "    java -version\n",
    "    </pre>\n",
    "    <i># Install Nextflow</i><pre>\n",
    "    curl https://get.nextflow.io | bash\n",
    "    chmod +x nextflow\n",
    "    ./nextflow self-update\n",
    "    ./nextflow plugin update\n",
    "    </pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883d1b1-ae4e-48dc-b146-e12f0793fc74",
   "metadata": {},
   "source": [
    "#### Create additional .config file needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the aws batch configuration file \n",
    "! cp nf-meripseq/conf/aws_batch_template.config aws_batch_submodule5.config \n",
    "# replace batch bucket name in nextflow configuration file\n",
    "! sed -i \"s/aws-batch-nigms-batch-bucket-/$BUCKET_NAME/g\" aws_batch_submodule5.config \n",
    "# replace job queue name in configuration file \n",
    "! sed -i \"s/aws-batch-nigms-JobQueue/$AWS_QUEUE/g\" aws_batch_submodule5.config \n",
    "# replace the region placeholder with your region\n",
    "! sed -i \"s/us-east-1/$AWS_REGION/g\" aws_batch_submodule5.config "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6424c54-108f-459e-8f14-f2866bfc0141",
   "metadata": {},
   "source": [
    "### Step 2. Enable AWS Batch for the nextflow script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb4617-b98c-41b6-995d-711d2f722cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run nextflow script with parameters \n",
    "! nextflow run nf-meripseq -profile docker,awsbatch \\\n",
    "    --input s3://$INPUT_FOLDER/samplesheet.csv \\\n",
    "    --fasta s3://$INPUT_FOLDER/chr11_1.5M.fasta \\\n",
    "    --gtf s3://$INPUT_FOLDER/gencode.v46.pri.chr11.1.5M.gtf \\\n",
    "    --genome hg38 \\\n",
    "    --read_length 37 \\\n",
    "    --contrast \"omental_tumor_vs_normal_Fallopian_tube\" \\\n",
    "    -c aws_batch_submodule5.config \\\n",
    "    -resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187f8dc-bcb6-4caf-b17c-183fc776147f",
   "metadata": {},
   "source": [
    "### Step 3: Explore Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39f248-77c0-4c98-8046-ac78a401c729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View output files that were output to S3 bucket\n",
    "! aws s3 ls s3://$BUCKET_NAME/nextflow_output/ --recursive | cut -c32-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d0630-1d85-4625-bc04-036aae11ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy output to local results folder (same outdir as if workflow was run locally)\n",
    "#! aws s3 sync s3://$BUCKET_NAME/nextflow_output/ meripseq-aws-batch-results/ --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cda66-9ceb-48f9-a446-6c4b0c0ce0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
